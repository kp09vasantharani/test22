# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-0

AWSTemplateFormatVersion: 2010-09-09

Description: 'Template to deploy Redshift and VPC with public and private subnet, and ingest data to Redshift'

Resources:

  # Lambda to ingest data to Redshift
  LambdaIngestFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Sub |
          import psycopg2
          from psycopg2 import ProgrammingError
          import boto3
          import json
          import cfnresponse
          def get_redshift_creds():
              print("get credentials")
              client = boto3.client('secretsmanager', region_name='${AWS::Region}')
              get_secret_value_response = client.get_secret_value(SecretId = "redshift-creds")
              secret = get_secret_value_response['SecretString']
              db_creds = json.loads(secret)
              return db_creds["username"], db_creds["password"]
          def create_conn(username, password):
              print("get connection")
              conn = psycopg2.connect(
                      dbname="dev",
                      user=username,
                      password=password,
                      port="5439",
                      host="redshiftcluster-pk9h2uggaevp.cqanaoi61lao.us-east-1.redshift.amazonaws.com"
              conn.autocommit = True
              return conn
          def run_query(conn, query):
              cursor = conn.cursor()
              cursor.execute(query)
              print("executed")
          def lambda_handler(event, context):
              print(event)
              if event["RequestType"] == "Delete":
                cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, {})
                return
              username, password = get_redshift_creds()
              conn = create_conn(username, password)
              run_query(conn, "DROP TABLE IF EXISTS public.orders CASCADE;")
              run_query(conn, "DROP TABLE IF EXISTS public.customer CASCADE;")
              run_query(conn, "DROP TABLE IF EXISTS public.nation CASCADE;")
              run_query(conn, """
                  CREATE TABLE public.nation (
                    N_NATIONKEY bigint NOT NULL PRIMARY KEY,
                    N_NAME varchar(25),
                    N_REGIONKEY bigint,
                    N_COMMENT varchar(152))
                  diststyle all;
              """)
              run_query(conn, """
                  create table public.customer (
                    C_CUSTKEY bigint NOT NULL PRIMARY KEY,
                    C_NAME varchar(25),
                    C_ADDRESS varchar(40),
                    C_NATIONKEY bigint REFERENCES nation(N_NATIONKEY),
                    C_PHONE varchar(15),
                    C_ACCTBAL decimal(18,4),
                    C_MKTSEGMENT varchar(10),
                    C_COMMENT varchar(117))
                  diststyle all;
              """)
              run_query(conn, """
                  create table public.orders (
                    O_ORDERKEY bigint NOT NULL PRIMARY KEY,
                    O_CUSTKEY bigint REFERENCES customer(C_CUSTKEY),
                    O_ORDERSTATUS varchar(1),
                    O_TOTALPRICE decimal(18,4),
                    O_ORDERDATE Date,
                    O_ORDERPRIORITY varchar(15),
                    O_CLERK varchar(15),
                    O_SHIPPRIORITY Integer,
                    O_COMMENT varchar(79))
                  distkey (O_ORDERKEY)
                  sortkey (O_ORDERDATE);
              """)
              run_query(conn, """
                  COPY public.nation FROM 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/nation/nation.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-west-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              run_query(conn, """
                  copy public.customer from 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/customer/customer.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-west-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              run_query(conn, """
                  copy public.orders from 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/orders/orders.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-west-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, {})
      Handler: "index.lambda_handler"
      Timeout: 900
      Role:
        Fn::GetAtt:
          - LambdaIngestFunctionRole
          - Arn
      Runtime: python3.7
      Layers:
        - !Ref LambdaLayer
        
  LambdaLayer:
    Type: AWS::Lambda::LayerVersion
    Properties: 
      CompatibleRuntimes: 
        - python3.7
      Content: 
        S3Bucket: aws-bigdata-blog
        S3Key: artifacts/automate-redshift-etl-dbt/python_libs.zip
      Description: Package for redshift connection
      LayerName: RedshiftUtil
      LicenseInfo: MIT

  LambdaIngestFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /

  LambdaAccessPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: LambdaDbtAccessPolicy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "secretsmanager:GetResourcePolicy"
              - "secretsmanager:GetSecretValue"
              - "secretsmanager:DescribeSecret"
            Resource:
              - !Ref RedshiftSecret
      Roles:
        - !Ref LambdaIngestFunctionRole  

  RedshiftDataIngestion:
    Type: Custom::RedshiftDataIngestion
    Properties:
      ServiceToken: !GetAtt LambdaIngestFunction.Arn

