# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-00

AWSTemplateFormatVersion: 2010-09-09

Description: 'Template to deploy Redshift and VPC with public and private subnet, and ingest data to Redshift'

Resources:

  ############# VPC, Private subnet, Public subnet ##################
  
  myCluster: 
  Type: "AWS::Redshift::Cluster"
  Properties:
    DBName: "mydb"
    MasterUsername: "master"
    MasterUserPassword: 
      Ref: "MasterUserPassword"
    NodeType: "ds2.xlarge"
    ClusterType: "single-node"
    Tags:
      - Key: foo
        Value: bar
  # Lambda to ingest data to Redshift
  LambdaIngestFunction:
    Type: AWS::Lambda::Function
    DependsOn:
    - Route2InternetGateway
    - Route2NatGateway
    - NetworkAclPrivateSubnet
    - NetworkAclPublicSubnet
    Properties:
      Code:
        ZipFile: !Sub |
          import psycopg2
          from psycopg2 import ProgrammingError
          import boto3
          import json
          import cfnresponse
          def get_redshift_creds():
              print("get credentials")
              client = boto3.client('secretsmanager', region_name='${AWS::Region}')
              get_secret_value_response = client.get_secret_value(SecretId = "redshift-creds")
              secret = get_secret_value_response['SecretString']
              db_creds = json.loads(secret)
              return db_creds["username"], db_creds["password"]
          def create_conn(username, password):
              print("get connection")
              conn = psycopg2.connect(
                      dbname="dev",
                      user=username,
                      password=password,
                      port="5439",
                      host="${RedshiftCluster.Endpoint.Address}")
              conn.autocommit = True
              return conn
          def run_query(conn, query):
              cursor = conn.cursor()
              cursor.execute(query)
              print("executed")
          def lambda_handler(event, context):
              print(event)
              if event["RequestType"] == "Delete":
                cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, {})
                return
              username, password = get_redshift_creds()
              conn = create_conn(username, password)
              run_query(conn, "DROP TABLE IF EXISTS public.orders CASCADE;")
              run_query(conn, "DROP TABLE IF EXISTS public.customer CASCADE;")
              run_query(conn, "DROP TABLE IF EXISTS public.nation CASCADE;")
              run_query(conn, """
                  CREATE TABLE public.nation (
                    N_NATIONKEY bigint NOT NULL PRIMARY KEY,
                    N_NAME varchar(25),
                    N_REGIONKEY bigint,
                    N_COMMENT varchar(152))
                  diststyle all;
              """)
              run_query(conn, """
                  create table public.customer (
                    C_CUSTKEY bigint NOT NULL PRIMARY KEY,
                    C_NAME varchar(25),
                    C_ADDRESS varchar(40),
                    C_NATIONKEY bigint REFERENCES nation(N_NATIONKEY),
                    C_PHONE varchar(15),
                    C_ACCTBAL decimal(18,4),
                    C_MKTSEGMENT varchar(10),
                    C_COMMENT varchar(117))
                  diststyle all;
              """)
              run_query(conn, """
                  create table public.orders (
                    O_ORDERKEY bigint NOT NULL PRIMARY KEY,
                    O_CUSTKEY bigint REFERENCES customer(C_CUSTKEY),
                    O_ORDERSTATUS varchar(1),
                    O_TOTALPRICE decimal(18,4),
                    O_ORDERDATE Date,
                    O_ORDERPRIORITY varchar(15),
                    O_CLERK varchar(15),
                    O_SHIPPRIORITY Integer,
                    O_COMMENT varchar(79))
                  distkey (O_ORDERKEY)
                  sortkey (O_ORDERDATE);
              """)
              run_query(conn, """
                  COPY public.nation FROM 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/nation/nation.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-east-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              run_query(conn, """
                  copy public.customer from 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/customer/customer.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-east-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              run_query(conn, """
                  copy public.orders from 's3://aws-bigdata-blog/artifacts/automate-redshift-etl-dbt/sample_data/orders/orders.tbl.'
                  iam_role '${RedshiftAccessRole.Arn}'
                  region 'us-east-1' lzop delimiter '|' COMPUPDATE PRESET;
              """)
              cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, {})
      Handler: "index.lambda_handler"
      Timeout: 900
      Role:
        Fn::GetAtt:
          - LambdaIngestFunctionRole
          - Arn
      Runtime: python3.7
      Layers:
        - !Ref LambdaLayer
      VpcConfig: 
        SubnetIds: 
          - !Ref PrivateSubnet
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup

  LambdaLayer:
    Type: AWS::Lambda::LayerVersion
    Properties: 
      CompatibleRuntimes: 
        - python3.7
      Content: 
        S3Bucket: aws-bigdata-blog
        S3Key: artifacts/automate-redshift-etl-dbt/python_libs.zip
      Description: Package for redshift connection
      LayerName: RedshiftUtil
      LicenseInfo: MIT

  LambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: EC2 Security Group for Lambda function
      VpcId:
        Ref: VPC

  LambdaToRedshiftSgRule:
    Type: AWS::EC2::SecurityGroupIngress
    Properties: 
      Description: Access from AWS Batch for DBT
      GroupId: !Ref RedshiftSecurityGroup 
      IpProtocol: tcp
      SourceSecurityGroupId: !Ref LambdaSecurityGroup
      FromPort: 5439
      ToPort: 5439

  LambdaIngestFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /

  LambdaAccessPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: LambdaDbtAccessPolicy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "secretsmanager:GetResourcePolicy"
              - "secretsmanager:GetSecretValue"
              - "secretsmanager:DescribeSecret"
            Resource:
              - !Ref RedshiftSecret
      Roles:
        - !Ref LambdaIngestFunctionRole  

  RedshiftDataIngestion:
    Type: Custom::RedshiftDataIngestion
    Properties:
      ServiceToken: !GetAtt LambdaIngestFunction.Arn

Outputs:
  VPC:
    Description: VPC ID
    Value: !Ref VPC
    Export:
      Name: !Sub "${AWS::StackName}-VPC"
  PrivateSubnet:
    Description: Private subnet ID
    Value: !Ref PrivateSubnet
    Export:
      Name: !Sub "${AWS::StackName}-PrivateSubnet"
  PublicSubnet:
    Description: Public subnet ID
    Value: !Ref PublicSubnet
    Export:
      Name: !Sub "${AWS::StackName}-PublicSubnet"
  RedshiftIamRole:
    Description: Name of IAM Role used by Reshift cluster
    Value: !GetAtt RedshiftAccessRole.Arn
  RedshiftClusterName:
    Description: Name of Redshift cluster
    Value: !Ref RedshiftCluster
  RedshiftSecurityGroup:
    Description: Security group of Redshift cluster
    Value: !Ref RedshiftSecurityGroup
    Export:
      Name: !Sub "${AWS::StackName}-RedshiftSecurityGroup"
  RedshiftClusterEndpoint:
    Description: Redshift cluster endpoint
    Value: !Sub "${RedshiftCluster.Endpoint.Address}"
    Export:
      Name: !Sub "${AWS::StackName}-RedshiftClusterEndpoint"
